\section{Implementation}
\label{sec:implementation}

In this section implementation of the RRLN system is considered. Thus, to make this possible Section~\ref{sec:heuristics} considers heuristics used to render the theoretical system implementable. Section~\ref{sec:experimental} considers experimental results.

\subsection{Heuristics}
\label{sec:heuristics}

\subsubsection{Tractability}
\label{sec:tractability}

It is not possible to map infinite state spaces in practice, so it is advantageous to set up $f_Q$ on a 
subspace.

The core goal during exploration of an MDP $M_i$ is to learn Q-values and use Q-values as a decision-making aid. 
\begin{enumerate}[label=\arabic*.]
\item Recall Section~\ref{sec}, encoding: $Q( s, a ) \leftarrow \sum_{s^\prime \in S}\tilde{R}(s^\prime|a,s)\tilde{T}(s^\prime|a,s)+\gamma Q( s^\prime, a )$
\item $\pi_t(s,a) = \frac{e^{Q(s,a)}}{\sum_{s^\prime \in S} 1+e^{Q(s,a)}}$, $\pi^\ast_t(s)=\argmax_{a} \pi( s, a )$
\end{enumerate}
Clearly exploring the space $S$ each iteration is impossible, thus $\mathbf{???}$ $\mathfrak{Z}$ as a local subset. Thus using $\mathfrak{Z}_{(S)}$ it is possible to use functions $f_Q$ and $f_m$ to regress to $Q( S \times A )$ images.
\begin{equation*}
\mathfrak{Z}_{(S)} \subseteq S \times A \times S
\end{equation*}
$\mathfrak{Z}_{(S)}$ is tractable size! and local!

\begin{equation*}
f_m: Q_{t+1}( S \times A ) \times Q_t(\mathfrak{Z}) \rightarrow Q_t(S\times A)
\end{equation*}

\subsubsection{Learning}
\label{sec:learning} 


We also need to keep $\tilde{T}$ and $\tilde{R}_t$ updated and can employ SGD regression instances to do this. As an MDP $M_i$ is exploring the environment the process in Section~\ref{sec:tractability} will always supply the latest and most up-to-date Q-values for decision-making. Thus, the values $\tilde{T}$ and $\tilde{R}$ must be updated online to facilitate this. To do so both $\tilde{T}$ and $\tilde{R}$ can be updated with stochastic gradient descent:
\begin{align*}
f_T: & \tilde{T}_{t-1}(\mathfrak{Z})\times\{s,a,s^\prime\}\rightarrow \tilde{T}_t(\mathfrak{Z}) \\
f_R: & \tilde{R}_{t-1}( \mathfrak{Z} ) \times \left\{  R( s^\prime | a, s ) \right\} \rightarrow \tilde{R}_t( \mathfrak{Z} )
\end{align*}
 

 
\textcircled{4} Implementation: I use instances of stochastic gradient descent to regress \fbox{$f_T$} and \fbox{$f_R$}

\begin{itemize}
\item $\tilde{T}_t(s^\prime | a, s ) \leftarrow f_T(s,a,s^\prime,T_{t-1}) = \tilde{T}_{t-1}(s^\prime|a,s)+\alpha_T\left(\frac{f_r(s,a,s^\prime)}{f_r(s,a)}-T_{t-1}(s^\prime|a,s)\right)$
\item
$\ldots\:\ldots\:\tilde{R}_t \leftarrow$ user defined / observed from sensors
\end{itemize}
where $f_r(s,a,s^\prime)$ and $f_r(s,a)$ reflect visitation frequencies.\\

$f_Q$ is more difficult, 
\begin{equation*}
f_m: Q_{t+1}(s,a) \leftarrow f_Q \left( \mathfrak{Z}, \tilde{T}_t, \tilde{R}_t \right) = \sum_{s^\prime \in \mathfrak{Z}} \tilde{T}(s^\prime|s,a) \tilde{R}(s^\prime|s,a) +\gamma V(s)
\end{equation*}
where $V(s)\approx \argmax_{a} Q_{t-1}(s,a)$. 
